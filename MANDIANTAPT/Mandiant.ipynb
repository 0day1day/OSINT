{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "APT-Maxmind-Enrichment-Product-2013-07-14-09-25-42.csv\t   get_fqdns.py  makmind2_test.py\tMandiant.ipynb\t\toutput\t      spitball.py\r\n",
        "APT-VirusTotal-Enrichment-Product-2013-07-14-21-37-16.csv  __init__.py\t mandiant_apt_list.txt\tnetworkx_clustering.py\tprobe_apt.py\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load spitball.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "__date__ = \"M, 2014\"\n",
      "__author__ = \"AlienOne\"\n",
      "__copyright__ = \"GPL\"\n",
      "__credits__ = [\"AlienOne\"]\n",
      "__license__ = \"GPL\"\n",
      "__version__ = \"0.0.5\"\n",
      "__maintainer__ = \"AlienOne\"\n",
      "__email__ = \"ali3n0ne@alienone.org\"\n",
      "__status__ = \"Prototype\"\n",
      "\n",
      "\n",
      "import requests\n",
      "import csv\n",
      "from pandas import DataFrame\n",
      "\n",
      "\n",
      "def getData():\n",
      "    \"\"\"Get CSV Mandiant Data Set - output list data structure\"\"\"\n",
      "    response = requests.get(\"https://raw.github.com/alienone/OSINT/master/MANDIANTAPT/APT-Maxmind-Enrichment-Product-2013-07-14-09-25-42.csv\")\n",
      "    iterResponse = response.iter_lines()\n",
      "    next(iterResponse)\n",
      "    for line in iterResponse:\n",
      "        yield line.split(',')\n",
      "\n",
      "\n",
      "def create_nodes(args=list):\n",
      "    \"\"\"Create list of dicts - each dict will represent a node\"\"\"\n",
      "    list_dicts = []\n",
      "    for prodList in getData():\n",
      "        if len(prodList[0]) != 0:\n",
      "            dict_object = dict(zip(args, prodList))\n",
      "            list_dicts.append(dict_object)\n",
      "    return list_dicts\n",
      "\n",
      "\n",
      "def clusterData(args, column_name):\n",
      "    \"\"\"Leverage Panadas Groupby to cluster nodes by ASN - Then convert resulting DataFrames into list dicts by cluster\"\"\"\n",
      "    gd = DataFrame(create_nodes(args)).groupby(column_name)\n",
      "    asn_groups = [x[0] for x in gd]\n",
      "    for asn in asn_groups:\n",
      "        df = gd.get_group(asn)\n",
      "        create_dict = [{k: df.values[i][v] for v, k in enumerate(df.columns)} for i in range(len(df))]\n",
      "        yield create_dict\n",
      "\n",
      "\n",
      "def normalize_cluster(cluster):\n",
      "    \"\"\"Return dicitonary object with value lists\"\"\"\n",
      "    normalized_cluster = {'ASN': [], 'FQDN': []}\n",
      "    del normalized_cluster['ASN'][:]\n",
      "    del normalized_cluster['FQDN'][:]\n",
      "    for node in cluster:\n",
      "        for k, v in node.items():\n",
      "            normalized_cluster[k].append(v)\n",
      "    return normalized_cluster\n",
      "\n",
      "\n",
      "def get_attributes(asn_str, csv_file):\n",
      "    \"\"\"Lookup additional attributes to add to final product\"\"\"\n",
      "    with open(csv_file, 'rb') as fh:\n",
      "        for item in fh:\n",
      "            data = item.split(',')\n",
      "            if asn_str in data:\n",
      "                    asn_ip = data[2]\n",
      "                    lat_lon = data[8:10]\n",
      "                    country = data[4:5]\n",
      "                    return lat_lon, country, asn_ip\n",
      "\n",
      "\n",
      "def normalized_nodes(csv_file):\n",
      "    \"\"\"Remove duplicates, add additional attributes\"\"\"\n",
      "    results_list = []\n",
      "    args = [\"FQDN\", \"ASN\"]\n",
      "    column_name = 'ASN'\n",
      "    for cluster in clusterData(args, column_name):\n",
      "        results_list.append(normalize_cluster(cluster))\n",
      "    for node in results_list:\n",
      "        asn_str = list(set(node['ASN']))[0]\n",
      "        keys = ['ASN', 'ASN IP', 'FQDN', 'LatLon', 'Locale']\n",
      "        values = list(set(node['ASN']))[0], get_attributes(asn_str, csv_file)[2], list(set(node['FQDN'])), \\\n",
      "        get_attributes(asn_str, csv_file)[0], \\\n",
      "                 get_attributes(asn_str, csv_file)[1][0]\n",
      "        dict_obj = dict(zip(keys, values))\n",
      "        yield dict_obj\n",
      "\n",
      "\n",
      "def main():\n",
      "    \"\"\"Display nodes and write Country, Latitude/Longitude to CSV for D3.js World Map Display\"\"\"\n",
      "    csv_file = \"APT-Maxmind-Enrichment-Product-2013-07-14-09-25-42.csv\"\n",
      "    for node in normalized_nodes(csv_file):\n",
      "        if 'Singapore' in node['Locale']:\n",
      "            print node\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'LatLon': ['1.3667', '103.8000'], 'Locale': 'Singapore', 'ASN IP': '54.254.124.68', 'ASN': '38895', 'FQDN': ['www.microsoft-update-info.com', 'nh.microsoft-update-info.com', 's.microsoft-update-info.com', 'e.microsoft-update-info.com', 'microsoft-update-info.com']}\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}